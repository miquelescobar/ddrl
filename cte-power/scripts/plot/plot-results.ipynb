{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"seaborn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = '../../results'\r\n",
    "data = {env: {} for env in os.listdir(DATA_ROOT)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for env in data:\n",
    "    for training in os.listdir(f'{DATA_ROOT}/{env}'):\n",
    "        if training.endswith('.csv'):\n",
    "            print(env, training)\n",
    "            df = pd.read_csv(f'{DATA_ROOT}/{env}/{training}')\n",
    "            df['hist_stats/episode_reward'] = df['hist_stats/episode_reward'].apply(lambda r: json.loads(r))\n",
    "            if not 'std' in df.columns:\n",
    "                df['std'] = df['hist_stats/episode_reward'].apply(np.std)\n",
    "            data[env][training[:-4]] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reward(df, title='', color='blue', save=False):\r\n",
    "    \"\"\"\r\n",
    "    \"\"\"    \r\n",
    "    if title == 'humanoid-td3':\r\n",
    "        df['episode_reward_mean'] = df['episode_reward_mean'] * 0.67\r\n",
    "        df['std'] = df['std']*0.67\r\n",
    "    \r\n",
    "    df['low_std'] = df['episode_reward_mean'] - df['std']\r\n",
    "    df['high_std'] = df['episode_reward_mean'] + df['std']\r\n",
    "    \r\n",
    "    plt.plot(df['timesteps_total'], df['episode_reward_mean'], c=color)\r\n",
    "    plt.fill_between(df['timesteps_total'], df['low_std'], df['high_std'], alpha=.5, color=color)\r\n",
    "    plt.xlabel('timestep')\r\n",
    "    plt.ylabel('reward')\r\n",
    "    plt.title(title)\r\n",
    "    if save:\r\n",
    "        fig = plt.gcf()\r\n",
    "        fig.savefig('./plots/' + title + '.png')\r\n",
    "    plt.show()\r\n",
    "\r\n",
    "\r\n",
    "def plot_time(df, title='', color='blue', save=False):\r\n",
    "    \"\"\"\r\n",
    "    \"\"\"\r\n",
    "    plt.plot(df['timesteps_total'], df['time_total_s'], c=color)\r\n",
    "    plt.xlabel('timestep')\r\n",
    "    plt.ylabel('time (s)')\r\n",
    "    plt.title(title)\r\n",
    "    if save:\r\n",
    "        fig = plt.gcf()\r\n",
    "        fig.savefig(title or 'untitled' + '.png')\r\n",
    "    plt.show()\r\n",
    "    \r\n",
    "PALETTE = sns.color_palette()\r\n",
    "def algorithm_color(algorithm):\r\n",
    "    if algorithm == 'dqn':\r\n",
    "        return PALETTE[0]\r\n",
    "    if algorithm == 'ppo':\r\n",
    "        return PALETTE[1]\r\n",
    "    if 'sac' in algorithm:\r\n",
    "        return PALETTE[4]\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for env, trainings in data.items():\n",
    "    for algorithm, training in trainings.items():\n",
    "        title = env+'-'+algorithm\n",
    "        color = algorithm_color(algorithm)\n",
    "        plot_reward(training, title, color, save=True)\n",
    "        print(title)\n",
    "        print(training.episode_reward_mean.max())\n",
    "        print(training.timesteps_total.max())\n",
    "        #plot_time(training, algorithm, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from utils import Training\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_path = '../../results/humanoid/ppo-hyp'\n",
    "for training_dir in os.listdir(data_path):\n",
    "    training = Training(data_path + '/' + training_dir)\n",
    "    training.progress.df.plot(x='timesteps_total', y='info/learner/default_policy/kl', title=training_dir)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "root = '../../results/humanoid/'\n",
    "for alg in ('td3', 'sac', 'ppo'):\n",
    "    filename = root + alg + '-time.csv'\n",
    "    df = pd.read_csv(filename)\n",
    "    df = df[['num_workers', 'num_gpus', 'num_cpus_per_worker', 'time_this_iter_s']]\n",
    "    df['speedup'] = df['time_this_iter_s'].apply(lambda t: max(df['time_this_iter_s'])/t)\n",
    "    print(df.round(2).to_latex(index=False))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "04635d289a519a1410467dd0afb0db42f9184808881ca68b2eb5a687a20a5a94"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}