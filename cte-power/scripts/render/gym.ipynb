{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "ENV_NAME = \"FrozenLake-v0\"\n",
    "GAMMA = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self):\n",
    "        self.env = gym.make(ENV_NAME)\n",
    "        self.V = np.zeros(self.env.observation_space.n)\n",
    "        \n",
    "    def calc_action_value(self, state, action):\n",
    "        action_value = sum([prob*(r + GAMMA * self.V[s_])\n",
    "            for prob, s_, r, _ in self.env.P[state][action]])\n",
    "        return action_value\n",
    "    \n",
    "    def select_action(self, state):\n",
    "        best_action, best_value = None, None\n",
    "        for action in range(self.env.action_space.n):\n",
    "            action_value = self.calc_action_value(state, action)\n",
    "            if best_value is None or best_value < action_value:\n",
    "                best_value = action_value\n",
    "                best_action = action\n",
    "        return best_action\n",
    "\n",
    "    def value_iteration(self):\n",
    "        for state in range(self.env.observation_space.n):\n",
    "            state_values = [self.calc_action_value(state, action)\n",
    "                            for action in range(self.env.action_space.n)\n",
    "                            ]\n",
    "            self.V[state] = max(state_values)\n",
    "        return self.V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_EPISODES = 40\n",
    "def check_improvements():\n",
    "    test_env = gym.make(ENV_NAME)\n",
    "    reward_test = 0.0\n",
    "    for _ in range(TEST_EPISODES):\n",
    "        total_reward = 0.0\n",
    "        state = test_env.reset()\n",
    "        while True:\n",
    "            action = agent.select_action(state)\n",
    "            new_state, new_reward, is_done, _ = test_env.step(action)\n",
    "            total_reward += new_reward\n",
    "            if is_done: break\n",
    "            state = new_state\n",
    "        reward_test += total_reward\n",
    "    reward_test /= TEST_EPISODES\n",
    "    return (reward_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "REWARD_THRESHOLD = 0.90\n",
    "def train(agent):\n",
    "    t = 0\n",
    "    best_reward = 0.0\n",
    "    while best_reward < REWARD_THRESHOLD:\n",
    "        agent.value_iteration()\n",
    "        t += 1\n",
    "        reward_test = check_improvements()\n",
    "        if reward_test > best_reward:\n",
    "            print(\"Best reward updated %.2f at iteration %d \" %\n",
    "                (reward_test ,t) )\n",
    "            best_reward = reward_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best reward updated 0.30 at iteration 3 \n",
      "Best reward updated 0.33 at iteration 5 \n",
      "Best reward updated 0.45 at iteration 6 \n",
      "Best reward updated 0.53 at iteration 8 \n",
      "Best reward updated 0.55 at iteration 12 \n",
      "Best reward updated 0.75 at iteration 13 \n",
      "Best reward updated 0.78 at iteration 16 \n",
      "Best reward updated 0.82 at iteration 17 \n",
      "Best reward updated 0.85 at iteration 34 \n",
      "Best reward updated 0.90 at iteration 56 \n"
     ]
    }
   ],
   "source": [
    "agent = Agent()\n",
    "train(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "FHFH\n",
      "F\u001b[41mF\u001b[0mFH\n",
      "HFFG\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "H\u001b[41mF\u001b[0mFG\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "H\u001b[41mF\u001b[0mFG\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HF\u001b[41mF\u001b[0mG\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HF\u001b[41mF\u001b[0mG\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFF\u001b[41mG\u001b[0m\n",
      "\n",
      "last state = 15\n",
      "reward =  1.0\n",
      "time steps = 11\n"
     ]
    }
   ],
   "source": [
    "def test(agent):\n",
    "    new_test_env = gym.make(ENV_NAME)\n",
    "    state = new_test_env.reset()\n",
    "    new_test_env.render()\n",
    "    is_done = False\n",
    "    t = 0\n",
    "    while not is_done:\n",
    "        action = agent.select_action(state)\n",
    "        new_state, reward, is_done, _ = new_test_env.step(action)\n",
    "        new_test_env.render()\n",
    "        state = new_state\n",
    "        t +=1\n",
    "    print(\"\\nlast state =\", state)\n",
    "    print(\"reward = \", reward)\n",
    "    print(\"time steps =\", t)\n",
    "\n",
    "test(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python37464bit7d8f1560eda44d7483159e2196aa1f7a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
